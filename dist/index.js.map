{"version":3,"sources":["../src/utils.ts","../src/api.ts","../src/client.ts","../src/types.ts"],"names":["ModelID"],"mappings":";;;AAQO,IAAM,eAAA,GAAkB,OAAA;AACxB,IAAM,gBAAA,GAAmB,QAAA;AACzB,IAAM,kBAAA,GAAqB,GAAA;AAK3B,IAAM,WAAA,GAAc,MAAA;AAKpB,IAAM,aAAA,GAAgB,kBAAA;AACtB,IAAM,oBAAA,GAA2C;AAAA,EACtD,MAAA,EAAQ,aAAA;AAAA,EACR,IAAA,EAAM,WAAA;AAAA,EACN,OAAA,EAAS,IAAA;AAAA,EACT,OAAA,EAAS;AAAA;AACX;AACO,IAAM,wBAAA,GAAyC;AAAA,EACpD,MAAA,EAAQ,oBAAA;AAAA,EACR,GAAA,EAAK;AACP,CAAA;AAMO,IAAM,gBAAA,GAAmB,CAAC,MAAA,KAAuC;AACtE,EAAA,MAAM,EAAE,IAAA,EAAM,MAAA,EAAO,GAAI,MAAA;AACzB,EAAA,MAAM,OAAO,IAAA,IAAQ,WAAA;AACrB,EAAA,MAAM,MAAA,GAAS,MAAA,KAAW,SAAA,GAAY,aAAA,GAAgB,MAAA,IAAU,aAAA;AAChE,EAAA,MAAM,MAAA,GAAS,CAAA,EAAG,MAAM,CAAA,CAAA,EAAI,IAAI,CAAA,CAAA;AAChC,EAAA,OAAO,MAAA;AACT,CAAA;;;ACrBO,IAAM,UAAU,OAAO;AAAA,EAC5B,MAAA;AAAA,EACA;AACF,CAAA,KAGyC;AACvC,EAAA,MAAM,OAAA,GAAU;AAAA,IACd,GAAI,MAAA,IAAU,EAAE,MAAA,EAAO;AAAA,IACvB,MAAA,EAAQ,KAAA;AAAA,IACR,OAAA,EAAS;AAAA,MACP,cAAA,EAAgB;AAAA;AAClB,GACF;AAEA,EAAA,IAAI;AACF,IAAA,MAAM,MAAA,GAAS,iBAAiB,MAAM,CAAA;AACtC,IAAA,MAAM,GAAA,GAAM,MAAM,KAAA,CAAM,CAAA,EAAG,MAAM,CAAA,CAAA,EAAI,MAAA,CAAO,OAAO,CAAA,QAAA,CAAA,EAAY,OAAO,CAAA;AACtE,IAAA,IAAI,CAAC,IAAI,EAAA,EAAI,MAAM,IAAI,KAAA,CAAM,CAAA,oBAAA,EAAuB,GAAA,CAAI,MAAM,CAAA,CAAE,CAAA;AAChE,IAAA,IAAI,CAAC,GAAA,EAAK,MAAM,IAAI,MAAM,uBAAuB,CAAA;AACjD,IAAA,OAAO,IAAI,IAAA,EAAK;AAAA,EAClB,SAAS,GAAA,EAAK;AACZ,IAAA,OAAA,CAAQ,KAAA,CAAM,kCAAkC,GAAG,CAAA;AACnD,IAAA,OAAO,IAAA;AAAA,EACT;AACF,CAAA;AAOO,IAAM,cAAA,GAAiB,CAC5B,MAAA,EACA,QAAA,KACyB;AACzB,EAAA,IAAI,CAAC,QAAA,IAAY,QAAA,CAAS,MAAA,KAAW,GAAG,OAAO,IAAA;AAE/C,EAAA,MAAM,cAAc,EAAC;AAGrB,EAAA,QAAA,CAAS,QAAQ,CAAA,GAAA,KAAO;AACtB,IAAA,MAAM,MAAA,GAAS,iBAAiB,MAAM,CAAA;AACtC,IAAA,MAAM,UAAU,GAAA,CAAI,IAAA;AACpB,IAAA,MAAM,YAIF,EAAC;AACL,IAAA,IAAI,GAAA;AAGJ,IAAA,GAAA,CAAI,SAAA,CAAU,QAAQ,CAAA,QAAA,KAAY;AAEhC,MAAA,MAAM,OAAA,GAAU,OACd,IAAA,KACG;AACH,QAAA,IAAI;AACF,UAAA,MAAM,WAAA,GAAc,EAAE,cAAA,EAAgB,kBAAA,EAAmB;AACzD,UAAA,MAAM,SAAS,QAAA,CAAS,MAAA;AACxB,UAAA,MAAM,OAAA,GAAU;AAAA,YACd,GAAI,MAAA,KAAW,MAAA,IAAU,CAAC,MAAM,QAAA,IAAY;AAAA,WAC9C;AACA,UAAA,MAAM,IAAA,GAAO,MAAM,QAAA,GACf,IAAA,CAAK,WACL,IAAA,CAAK,SAAA,CAAU,MAAM,IAAI,CAAA;AAC7B,UAAA,MAAM,SAAS,IAAA,EAAM,MAAA;AACrB,UAAA,MAAM,WAAA,GAAc,MAAM,WAAA,GACtB,IAAI,gBAAgB,IAAA,EAAM,WAAW,CAAA,CAAE,QAAA,EAAS,GAChD,IAAA;AACJ,UAAA,MAAM,QAAA,GAAW,WAAA,GAAc,CAAA,CAAA,EAAI,WAAW,CAAA,CAAA,GAAK,EAAA;AACnD,UAAA,MAAM,MAAM,CAAA,EAAG,MAAM,GAAG,QAAA,CAAS,OAAO,GAAG,QAAQ,CAAA,CAAA;AAEnD,UAAA,GAAA,GAAM,MAAM,MAAM,GAAA,EAAK;AAAA,YACrB,MAAA;AAAA,YACA,IAAA,EAAM,MAAA;AAAA;AAAA,YACN,KAAA,EAAO,UAAA;AAAA,YACP,WAAA,EAAa,aAAA;AAAA,YACb,OAAA;AAAA;AAAA,YACA,QAAA,EAAU,QAAA;AAAA,YACV,cAAA,EAAgB,aAAA;AAAA;AAAA,YAChB,IAAA;AAAA,YACA,GAAI,MAAA,IAAU,EAAE,MAAA;AAAO,WACxB,CAAA;AAGD,UAAA,IAAI,CAAC,GAAA;AACH,YAAA,MAAM,IAAI,KAAA,CAAM,CAAA,yBAAA,EAA4B,QAAA,CAAS,IAAI,CAAA,CAAA,CAAG,CAAA;AAG9D,UAAA,IAAI,CAAC,KAAK,EAAA,EAAI;AAEZ,YAAA,IAAI,cAAc,GAAA,EAAK,UAAA;AACvB,YAAA,IAAI;AACF,cAAA,MAAM,SAAA,GAAY,MAAM,GAAA,CAAI,IAAA,EAAK;AACjC,cAAA,IAAI,WAAW,MAAA,EAAQ;AACrB,gBAAA,WAAA,GACE,OAAO,UAAU,MAAA,KAAW,QAAA,GACxB,UAAU,MAAA,GACV,IAAA,CAAK,SAAA,CAAU,SAAA,CAAU,MAAM,CAAA;AAAA,cACvC,CAAA,MAAA,IAAW,WAAW,OAAA,EAAS;AAC7B,gBAAA,WAAA,GAAc,SAAA,CAAU,OAAA;AAAA,cAC1B;AAAA,YACF,CAAA,CAAA,MAAQ;AAAA,YAER;AACA,YAAA,MAAM,IAAI,KAAA,CAAM,CAAA,sBAAA,EAAyB,WAAW,CAAA,CAAE,CAAA;AAAA,UACxD;AAGA,UAAA,MAAM,YAAA,GAAe,GAAA,CAAI,OAAA,CAAQ,GAAA,CAAI,cAAc,CAAA;AACnD,UAAA,IAAI,IAAI,IAAA,IAAQ,CAAC,YAAA,EAAc,QAAA,CAAS,cAAc,CAAA,EAAG;AACvD,YAAA,MAAM,MAAA,GAAS,MAAM,GAAA,CAAI,IAAA,EAAK;AAE9B,YAAA,IAAI,CAAC,MAAA,EAAQ,MAAM,IAAI,MAAM,sBAAsB,CAAA;AAEnD,YAAA,IAAI,OAAO,MAAA,EAAQ,OAAA,KAAY,SAAA,IAAa,CAAC,MAAA,EAAQ,OAAA;AACnD,cAAA,MAAM,IAAI,KAAA;AAAA,gBACR,qCACE,QAAA,CAAS,IACX,eAAe,MAAA,EAAQ,OAAA,IAAW,QAAQ,MAAM,CAAA;AAAA,eAClD;AAEF,YAAA,OAAO,MAAA;AAAA,UACT;AAEA,UAAA,OAAO,GAAA;AAAA,QACT,SAAS,GAAA,EAAK;AACZ,UAAA,OAAA,CAAQ,KAAA,CAAM,CAAA,kBAAA,EAAqB,QAAA,CAAS,IAAI,MAAM,GAAG,CAAA;AACzD,UAAA,OAAO,EAAE,OAAA,EAAS,KAAA,EAAO,OAAA,EAAS,GAAA,EAAI;AAAA,QACxC;AAAA,MACF,CAAA;AAGA,MAAA,SAAA,CAAU,QAAA,CAAS,IAAI,CAAA,GAAI,OAAA;AAE3B,MAAA,SAAA,CAAU,OAAA,GAAU,GAAA,CAAI,OAAA,IAAW,EAAC;AAAA,IACtC,CAAC,CAAA;AAED,IAAA,WAAA,CAAY,OAAO,CAAA,GAAI,SAAA;AAAA,EACzB,CAAC,CAAA;AAED,EAAA,OAAO,WAAA;AACT,CAAA;AAMO,IAAM,cAAA,GAAiB,OAC5B,MAAA,KAC4B;AAC5B,EAAA,MAAM,OAAA,GAAU;AAAA,IACd,MAAA,EAAQ,KAAA;AAAA,IACR,OAAA,EAAS;AAAA,MACP,cAAA,EAAgB;AAAA;AAClB,GACF;AAEA,EAAA,IAAI;AACF,IAAA,MAAM,QAAA,GAAW,CAAA,CAAA,EAAI,MAAA,CAAO,OAAO,CAAA,aAAA,CAAA;AACnC,IAAA,MAAM,GAAA,GAAM,iBAAiB,MAAM,CAAA;AACnC,IAAA,MAAM,GAAA,GAAM,MAAM,KAAA,CAAM,CAAA,EAAG,GAAG,CAAA,EAAG,QAAQ,IAAI,OAAO,CAAA;AACpD,IAAA,IAAI,CAAC,IAAI,EAAA,EAAI,MAAM,IAAI,KAAA,CAAM,CAAA,oBAAA,EAAuB,GAAA,CAAI,MAAM,CAAA,CAAE,CAAA;AAChE,IAAA,IAAI,CAAC,GAAA,EAAK,MAAM,IAAI,KAAA,CAAM,CAAA,iBAAA,EAAoB,QAAQ,CAAA,CAAE,CAAA;AACxD,IAAA,MAAM,MAAA,GAA6B,MAAM,GAAA,CAAI,IAAA,EAAK;AAClD,IAAA,MAAM,UAAU,MAAA,EAAQ,OAAA;AACxB,IAAA,IAAI,CAAC,SAAS,OAAO,IAAA;AACrB,IAAA,MAAM,OAAO,MAAA,CAAO,IAAA;AACpB,IAAA,OAAO,IAAA;AAAA,EACT,SAAS,GAAA,EAAK;AACZ,IAAA,OAAA,CAAQ,KAAA,CAAM,iCAAiC,GAAG,CAAA;AAClD,IAAA,OAAO,IAAA;AAAA,EACT;AACF,CAAA;;;ACzKA,IAAM,cAAN,MAAkB;AAAA,EAAlB,WAAA,GAAA;AACE,IAAA,IAAA,CAAQ,YAAA,GAAe,KAAA;AACvB,IAAA,IAAA,CAAQ,eAAA,GAA0C,IAAA;AAClD,IAAA,IAAA,CAAQ,UAAA,GAA2B,wBAAA;AAAA,EAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOnC,WAAA,GAAuB;AACrB,IAAA,OACE,IAAA,CAAK,gBACL,CAAC,CAAC,KAAK,UAAA,CAAW,GAAA,IAClB,IAAA,CAAK,UAAA,CAAW,MAAA,CAAO,OAAA;AAAA,EAE3B;AAAA;AAAA;AAAA;AAAA,EAKA,aAAA,GAA8B;AAC5B,IAAA,OAAO,IAAA,CAAK,UAAA;AAAA,EACd;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,OAAA,CAAQ;AAAA,IACZ,MAAA;AAAA,IACA;AAAA,GACF,EAGqB;AACnB,IAAA,IAAI,KAAK,YAAA,EAAc;AACrB,MAAA,OAAA,CAAQ,IAAI,8CAA8C,CAAA;AAC1D,MAAA,OAAO,KAAA;AAAA,IACT;AACA,IAAA,IAAI;AAEF,MAAA,MAAM,WAAA,GAAc,MAAM,OAAA,CAAW;AAAA,QACnC,MAAA;AAAA,QACA,GAAI,MAAA,IAAU,EAAE,MAAA;AAAO,OACxB,CAAA;AACD,MAAA,IAAI,CAAC,WAAA,EAAa,OAAA,QAAe,IAAI,KAAA,CAAM,aAAa,OAAO,CAAA;AAE/D,MAAA,MAAM,SAAA,GAAY,MAAM,cAAA,CAAe,MAAM,CAAA;AAC7C,MAAA,IAAI,CAAC,SAAA,EAAW,MAAM,IAAI,MAAM,kBAAkB,CAAA;AAClD,MAAA,MAAM,WAAA,GAAc,cAAA,CAAe,MAAA,EAAQ,SAAS,CAAA;AAEpD,MAAA,IAAI,WAAA,EAAa;AACf,QAAA,IAAA,CAAK,YAAA,GAAe,IAAA;AAEpB,QAAA,MAAM,aAAA,GAAgB,EAAE,GAAG,MAAA,EAAQ,SAAS,IAAA,EAAK;AACjD,QAAA,IAAA,CAAK,UAAA,GAAa,EAAE,MAAA,EAAQ,aAAA,EAAe,KAAK,WAAA,EAAY;AAC5D,QAAA,OAAA,CAAQ,GAAA;AAAA,UACN,sDAAA;AAAA,UACA;AAAA,SACF;AACA,QAAA,OAAO,IAAA;AAAA,MACT;AAEA,MAAA,OAAO,KAAA;AAAA,IACT,SAAS,KAAA,EAAO;AACd,MAAA,OAAA,CAAQ,KAAA,CAAM,8CAA8C,KAAK,CAAA;AACjE,MAAA,IAAA,CAAK,YAAA,GAAe,KAAA;AACpB,MAAA,OAAO,KAAA;AAAA,IACT;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,IAAA,CAAK,OAAA,GAAU,GAAA,EAIlB;AAGD,IAAA,MAAM,UAAA,GAAa,IAAI,eAAA,EAAgB;AACvC,IAAA,MAAM,YAAY,UAAA,CAAW,MAAM,UAAA,CAAW,KAAA,IAAS,OAAO,CAAA;AAC9D,IAAA,MAAM,SAAA,GAAY,YAAY,GAAA,EAAI;AAElC,IAAA,IAAI;AACF,MAAA,MAAM,WAAA,GAAc,MAAM,OAAA,CAAW;AAAA,QACnC,MAAA,EAAQ,KAAK,UAAA,CAAW,MAAA;AAAA,QACxB,QAAQ,UAAA,CAAW;AAAA,OACpB,CAAA;AACD,MAAA,YAAA,CAAa,SAAS,CAAA;AAEtB,MAAA,IAAI,CAAC,WAAA,EAAa,OAAA,QAAe,IAAI,KAAA,CAAM,aAAa,OAAO,CAAA;AAC/D,MAAA,OAAO;AAAA,QACL,OAAA,EAAS,IAAA;AAAA,QACT,cAAc,IAAA,CAAK,KAAA,CAAM,WAAA,CAAY,GAAA,KAAQ,SAAS;AAAA,OACxD;AAAA,IACF,SAAS,KAAA,EAAO;AACd,MAAA,YAAA,CAAa,SAAS,CAAA;AACtB,MAAA,OAAO;AAAA,QACL,OAAA,EAAS,KAAA;AAAA,QACT,KAAA,EAAO,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU;AAAA,OAClD;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,aAAA,GAAsB;AACpB,IAAA,IAAI,KAAK,eAAA,EAAiB;AACxB,MAAA,IAAA,CAAK,gBAAgB,KAAA,EAAM;AAC3B,MAAA,IAAA,CAAK,eAAA,GAAkB,IAAA;AAAA,IACzB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,UAAA,GAAmB;AACjB,IAAA,IAAA,CAAK,aAAA,EAAc;AACnB,IAAA,IAAA,CAAK,WAAW,GAAA,GAAM,IAAA;AACtB,IAAA,IAAA,CAAK,YAAA,GAAe,KAAA;AAAA,EACtB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,wBAAwB,QAAA,EAAuB;AAErD,IAAA,IAAI,SAAS,IAAA,EAAM;AACjB,MAAA,OAAO,QAAA,CAAS,IAAA;AAAA,IAClB;AAGA,IAAA,IAAI,SAAS,QAAA,EAAU;AACrB,MAAA,OAAO,QAAA,CAAS,QAAA;AAAA,IAClB;AAGA,IAAA,IAAI,QAAA,CAAS,IAAA,IAAQ,OAAO,QAAA,CAAS,SAAS,QAAA,EAAU;AACtD,MAAA,OAAO,QAAA,CAAS,IAAA;AAAA,IAClB;AAGA,IAAA,IAAI,SAAS,OAAA,IAAW,KAAA,CAAM,OAAA,CAAQ,QAAA,CAAS,OAAO,CAAA,EAAG;AACvD,MAAA,OACE,QAAA,CAAS,OAAA,CAAQ,CAAC,CAAA,EAAG,IAAA,IAAQ,SAAS,OAAA,CAAQ,CAAC,CAAA,EAAG,OAAA,EAAS,OAAA,IAAW,EAAA;AAAA,IAE1E;AAGA,IAAA,OAAO,OAAO,QAAQ,CAAA;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAc,oBAAA,CACZ,QAAA,EACA,OAAA,EAOA,QAAA,EACiB;AACjB,IAAA,MAAM,MAAA,GAAS,QAAA,CAAS,IAAA,EAAM,SAAA,EAAU;AACxC,IAAA,IAAI,CAAC,MAAA,EAAQ;AACX,MAAA,MAAM,IAAI,MAAM,4CAA4C,CAAA;AAAA,IAC9D;AAEA,IAAA,MAAM,OAAA,GAAU,IAAI,WAAA,CAAY,OAAO,CAAA;AACvC,IAAA,IAAI,QAAA,GAAW,EAAA;AACf,IAAA,MAAM,WAAA,GAAc,SAAS,WAAA,IAAe,IAAA;AAE5C,IAAA,IAAI;AACF,MAAA,IAAI,aAAA,GAAgB,MAAM,MAAA,CAAO,IAAA,EAAK;AAGtC,MAAA,OAAO,CAAC,aAAA,CAAc,IAAA,IAAQ,CAAC,QAAA,EAAU,OAAO,OAAA,EAAS;AACvD,QAAA,IAAI;AACF,UAAA,MAAM,KAAA,GACJ,OAAO,aAAA,CAAc,KAAA,KAAU,WAC3B,aAAA,CAAc,KAAA,GACd,OAAA,CAAQ,MAAA,CAAO,aAAA,CAAc,KAAA,EAAO,EAAE,MAAA,EAAQ,MAAM,CAAA;AAE1D,UAAA,MAAM,KAAA,GAAQ,KAAA,CAAM,KAAA,CAAM,IAAI,CAAA;AAE9B,UAAA,KAAA,MAAW,QAAQ,KAAA,EAAO;AAExB,YAAA,IAAI,IAAA,EAAM,UAAA,CAAW,kBAAkB,CAAA,EAAG;AACxC,cAAA,MAAM,UAAU,IAAA,CAAK,KAAA,CAAM,kBAAA,CAAmB,MAAM,EAAE,IAAA,EAAK;AAC3D,cAAA,MAAM,OAAA,EAAS,YAAY,OAAO,CAAA;AAAA,YACpC;AAGA,YAAA,IAAI,IAAA,EAAM,UAAA,CAAW,gBAAgB,CAAA,EAAG;AACtC,cAAA,MAAM,YAAY,IAAA,CAAK,KAAA,CAAM,gBAAA,CAAiB,MAAM,EAAE,IAAA,EAAK;AAC3D,cAAA,MAAM,OAAA,EAAS,UAAU,SAAS,CAAA;AAAA,YACpC;AAGA,YAAA,IAAI,IAAA,EAAM,UAAA,CAAW,eAAe,CAAA,EAAG;AACrC,cAAA,MAAM,YAAY,IAAA,CAAK,KAAA,CAAM,eAAA,CAAgB,MAAM,EAAE,IAAA,EAAK;AAG1D,cAAA,IAAI,cAAc,QAAA,EAAU;AAC1B,gBAAA;AAAA,cACF;AAGA,cAAA,MAAM,OAAA,EAAS,SAAS,SAAS,CAAA;AAGjC,cAAA,IAAI,WAAA,EAAa;AACf,gBAAA,IAAI;AACF,kBAAA,MAAM,MAAA,GAAS,IAAA,CAAK,KAAA,CAAM,SAAS,CAAA;AACnC,kBAAA,QAAA,IAAY,IAAA,CAAK,wBAAwB,MAAM,CAAA;AAAA,gBACjD,CAAA,CAAA,MAAQ;AAEN,kBAAA,QAAA,IAAY,SAAA;AAAA,gBACd;AAAA,cACF;AAAA,YACF;AAGA,YAAA,IACE,CAAC,KAAK,UAAA,CAAW,eAAe,KAChC,IAAA,CAAK,UAAA,CAAW,QAAQ,CAAA,EACxB;AACA,cAAA,MAAM,IAAA,GAAO,IAAA,CAAK,KAAA,CAAM,CAAC,CAAA;AACzB,cAAA,IAAI,SAAS,QAAA,EAAU;AAEvB,cAAA,MAAM,OAAA,EAAS,SAAS,IAAI,CAAA;AAE5B,cAAA,IAAI,WAAA,EAAa;AACf,gBAAA,IAAI;AACF,kBAAA,MAAM,MAAA,GAAS,IAAA,CAAK,KAAA,CAAM,IAAI,CAAA;AAC9B,kBAAA,QAAA,IAAY,IAAA,CAAK,wBAAwB,MAAM,CAAA;AAAA,gBACjD,CAAA,CAAA,MAAQ;AACN,kBAAA,QAAA,IAAY,IAAA;AAAA,gBACd;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAAA,QACF,SAAS,GAAA,EAAK;AACZ,UAAA,OAAA,CAAQ,GAAA,CAAI,oDAAoD,GAAG,CAAA;AAAA,QACrE;AAEA,QAAA,aAAA,GAAgB,MAAM,OAAO,IAAA,EAAK;AAAA,MACpC;AAGA,MAAA,IAAI,CAAC,cAAc,IAAA,EAAM;AACvB,QAAA,MAAM,OAAO,MAAA,EAAO;AAAA,MACtB;AAAA,IACF,CAAA,SAAE;AACA,MAAA,MAAA,CAAO,WAAA,EAAY;AAAA,IACrB;AAGA,IAAA,MAAM,SAAS,QAAA,IAAW;AAE1B,IAAA,OAAO,QAAA;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,WAAA,CACJ,QAAA,EACA,OAAA,EACiB;AACjB,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAGA,IAAA,IAAA,CAAK,eAAA,GAAkB,IAAI,eAAA,EAAgB;AAE3C,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,cAAc,QAAA,CAAS;AAAA,QAClE,IAAA,EAAM;AAAA,UACJ,QAAA;AAAA,UACA,YAAA,EAAc,MAAA;AAAA,UACd,WAAA,EAAa,GAAA;AAAA,UACb,UAAA,EAAY,IAAA;AAAA,UACZ,MAAA,EAAQ,KAAA;AAAA;AAAA,UACR,GAAG;AAAA,SACL;AAAA,QACA,MAAA,EAAQ,KAAK,eAAA,CAAgB;AAAA,OAC9B,CAAA;AAED,MAAA,IAAI,CAAC,QAAA,EAAU;AACb,QAAA,MAAM,IAAI,MAAM,6BAA6B,CAAA;AAAA,MAC/C;AAGA,MAAA,IAAI,OAAO,aAAa,QAAA,EAAU;AAChC,QAAA,OAAO,QAAA;AAAA,MACT;AAIA,MAAA,IACE,OAAO,aAAa,QAAA,IACpB,QAAA,KAAa,QACb,SAAA,IAAa,QAAA,IACb,UAAU,QAAA,EACV;AACA,QAAA,MAAM,YAAA,GAAe,QAAA;AACrB,QAAA,MAAM,WAAA,GAAc,YAAA,CAAa,OAAA,CAAQ,GAAA,CAAI,cAAc,CAAA;AAC3D,QAAA,IAAI,WAAA,EAAa,QAAA,CAAS,cAAc,CAAA,EAAG;AAEzC,UAAA,OAAO,MAAM,IAAA,CAAK,oBAAA,CAAqB,YAAY,CAAA;AAAA,QACrD,CAAA,MAAO;AAEL,UAAA,MAAM,IAAA,GAAO,MAAM,YAAA,CAAa,IAAA,EAAK;AACrC,UAAA,OAAO,IAAA,CAAK,wBAAwB,IAAI,CAAA;AAAA,QAC1C;AAAA,MACF;AAGA,MAAA,OAAO,IAAA,CAAK,wBAAwB,QAAQ,CAAA;AAAA,IAC9C,SAAS,KAAA,EAAO;AACd,MAAA,IAAI,KAAA,YAAiB,KAAA,IAAS,KAAA,CAAM,IAAA,KAAS,YAAA,EAAc;AACzD,QAAA,MAAM,IAAI,MAAM,uBAAuB,CAAA;AAAA,MACzC;AACA,MAAA,MAAM,KAAA;AAAA,IACR;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,iBAAA,CAAkB;AAAA,IAChB,MAAA;AAAA,IACA;AAAA,GACF,EAGG;AACD,IAAA,OAAA,CAAQ,IAAI,qCAAqC,CAAA;AACjD,IAAA,MAAM,IAAA,GAAO,IAAA,CAAK,uBAAA,CAAwB,MAAM,CAAA;AAChD,IAAA,IAAI,IAAA,oBAAwB,IAAI,CAAA;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,cAAA,CAAe;AAAA,IACnB,MAAA;AAAA,IACA;AAAA,GACF,EAGG;AACD,IAAA,IAAI;AAEF,MAAA,MAAM,YAAA,GAAe,MAAA,GAAS,IAAA,CAAK,KAAA,CAAM,MAAM,CAAA,GAAI,IAAA;AACnD,MAAA,MAAM,OAAO,YAAA,EAAc,IAAA;AAC3B,MAAA,MAAM,YAAY,YAAA,EAAc,KAAA;AAGhC,MAAA,MAAM,IAAA,GAAO,IAAA,CAAK,uBAAA,CAAwB,IAAA,IAAQ,YAAY,CAAA;AAE9D,MAAA,IAAI,IAAA;AACF,QAAA,eAAA,GAAkB,CAAA,QAAA,KAAY;AAE5B,UAAA,IAAI,SAAA,KAAc,sBAAsB,OAAO,IAAA;AAC/C,UAAA,OAAQ,QAAA,IAAY,IAAA;AAAA,QACtB,CAAC,CAAA;AACH,MAAA;AAAA,IACF,SAAS,GAAA,EAAK;AACZ,MAAA,OAAA,CAAQ,GAAA;AAAA,QACN,oCAAA;AAAA,QACA,OAAO,MAAA;AAAA,QACP,KAAA;AAAA,QACA;AAAA,OACF;AACA,MAAA;AAAA,IACF;AAAA,EACF;AAAA,EAEA,cAAc,SAAA,EAAmB;AAW/B,IAAA,OAAA,CAAQ,GAAA,CAAI,CAAA,6BAAA,EAAgC,SAAS,CAAA,CAAE,CAAA;AAAA,EACzD;AAAA,EAEA,MAAM,MAAA,CACJ,MAAA,EACA,aAAA,EACA,YAAA,EACA;AACA,IAAA,IAAI,CAAC,MAAA,EAAQ;AAMb,IAAA,MAAM,UAAA,GAAwB;AAAA,MAC5B,IAAI,MAAA,CAAO,EAAA;AAAA,MACX,MAAM,MAAA,CAAO,IAAA;AAAA,MACb,SAAS,MAAA,CAAO,OAAA;AAAA;AAAA,MAChB,WAAW,MAAA,CAAO,SAAA;AAAA,MAClB,GAAI,OAAO,IAAA,KAAS,MAAA,IAAU,EAAE,QAAA,EAAU,MAAA,EAAQ,YAAY,EAAA,EAAG;AAAA,MACjE,GAAI,OAAO,IAAA,KAAS,WAAA,IAAe,EAAE,OAAA,EAAS,MAAA,EAAQ,WAAW,EAAA;AAAG,KACtE;AAaA,IAAA,IAAI;AAOF,MAAA,OAAA,CAAQ,GAAA;AAAA,QACN,uDAAA;AAAA,QACA;AAAA,OACF;AAiBA,MAAA,MAAM,WAAW,EAAC;AAIlB,MAAA,IAAI,QAAA,EAAU,MAAM,SAAA,EAAW;AAE7B,QAAA,MAAM,IAAA,CAAK,oBAAA;AAAA,UACT,QAAA;AAAA,UACA;AAAA,YACE,MAAA,EAAQ,CAAC,GAAA,KAAgB,IAAA,CAAK,eAAe,EAAE,MAAA,EAAQ,KAAK,CAAA;AAAA,YAC5D,UAAU,YAAY;AACpB,cAAA,OAAA,CAAQ,IAAI,iCAAiC,CAAA;AAC7C,cAAA;AAAA,YACF,CAAA;AAAA,YACA,OAAA,EAAS,OAAO,GAAA,KAAgB;AAC9B,cAAA,IAAA,CAAK,cAAc,GAAG,CAAA;AACtB,cAAA,MAAM,eAAA,GAAkB,GAAA,CAAI,OAAA,CAAQ,IAAA,EAAM,GAAG,CAAA,GAAI,KAAA;AACjD,cAAA,IAAI,GAAA,gBAAmB,eAAe,CAAA;AAAA,YACxC,CAAA;AAAA,YACA,SAAA,EAAW,OAAO,GAAA,KAAgB;AAChC,cAAA,OAAA,CAAQ,GAAA,CAAI,4BAA4B,GAAG,CAAA;AAC3C,cAAA;AAAA,YACF,CAAA;AAAA,YACA,WAAA,EAAa;AAAA;AAAA,WACf;AAAA,UACA,IAAA,CAAK;AAAA,SACP;AAAA,MACF,OAGK,IAAA,CAAK,iBAAA,CAAkB,EAAE,MAAA,EAAQ,UAAU,CAAA;AAMhD,MAAA,YAAA,CAAa,KAAK,CAAA;AAClB,MAAA;AAAA,IACF,SAAS,GAAA,EAAK;AACZ,MAAA,YAAA,CAAa,KAAK,CAAA;AAClB,MAAA,OAAA,CAAQ,GAAA,CAAI,CAAA,eAAA,EAAkB,GAAG,CAAA,CAAE,CAAA;AAAA,IAErC;AAAA,EACF;AAAA;AAAA,EAIA,QAAA,GAAW;AACT,IAAA,IAAA,CAAK,iBAAiB,KAAA,EAAM;AAC5B,IAAA,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,aAAA,CAAc,IAAA,EAAK;AAAA,EAC3C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,YAAA,CAAa,MAAA,EAAgB,QAAA,EAAoC;AACrE,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AAEF,MAAA,MAAM,IAAA,GAA+C,EAAE,OAAA,EAAS,MAAA,EAAO;AACvE,MAAA,IAAI,QAAA,EAAU;AACZ,QAAA,IAAA,CAAK,QAAA,GAAW,QAAA;AAAA,MAClB;AAEA,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,cAAc,QAAA,CAAS;AAAA,QAClE;AAAA,OACD,CAAA;AAID,MAAA,IAAI,UAAU,OAAA,EAAS;AACrB,QAAA,OAAO,QAAA,CAAS,OAAA;AAAA,MAClB;AAGA,MAAA,IAAI,UAAU,IAAA,EAAM;AAClB,QAAA,OAAO,QAAA,CAAS,IAAA;AAAA,MAClB;AAEA,MAAA,MAAM,IAAI,MAAM,0CAA0C,CAAA;AAAA,IAC5D,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,yBAAA,EAA4B,OAAO,CAAA,CAAE,CAAA;AAAA,IACvD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,cAAA,CAAe,MAAA,EAAgB,QAAA,EAAiC;AACpE,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,aAAA,CAAc,MAAA,CAAO;AAAA,QAC/C,IAAA,EAAM;AAAA,UACJ,MAAA;AAAA,UACA;AAAA;AACF,OACD,CAAA;AAAA,IACH,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,2BAAA,EAA8B,OAAO,CAAA,CAAE,CAAA;AAAA,IACzD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAeA,MAAM,SAAA,CAAU,SAAA,EAAmB,OAAA,EAAgC;AACjE,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,UAAU,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,cAAc,IAAA,CAAK;AAAA,QAC7D,IAAA,EAAM;AAAA,UACJ,SAAA;AAAA,UACA,OAAA;AAAA,UACA,IAAA,EAAM;AAAA,YACJ,KAAA,EAAO,IAAA;AAAA,YACP,SAAA,EAAW,CAAA;AAAA,YACX,YAAA,EAAc,CAAA;AAAA,WAChB;AAAA,UACA,IAAA,EAAM;AAAA,YACJ,WAAA,EAAa,GAAA;AAAA,YACb,UAAA,EAAY;AAAA;AACd;AACF,OACD,CAAA;AACD,MAAA,IAAI,CAAC,OAAA,EAAS,MAAM,IAAI,MAAM,8BAA8B,CAAA;AAAA,IAC9D,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,sBAAA,EAAyB,OAAO,CAAA,CAAE,CAAA;AAAA,IACpD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,WAAA,GAA6B;AACjC,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,aAAA,CAAc,MAAA,EAAO;AAAA,IACnD,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,wBAAA,EAA2B,OAAO,CAAA,CAAE,CAAA;AAAA,IACtD;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,cAAA,GAAiB;AACrB,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,cAAc,KAAA,EAAM;AACjE,MAAA,OAAO,UAAU,IAAA,IAAQ,IAAA;AAAA,IAC3B,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,4BAAA,EAA+B,OAAO,CAAA,CAAE,CAAA;AAAA,IAC1D;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,kBAAA,GAAsD;AAC1D,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,cAAc,SAAA,EAAU;AACrE,MAAA,MAAM,SAAS,QAAA,EAAU,IAAA;AACzB,MAAA,IAAI,CAAC,UAAU,MAAA,CAAO,MAAA,IAAU,GAAG,MAAM,IAAI,MAAM,aAAa,CAAA;AAChE,MAAA,OAAO,MAAA;AAAA,IACT,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,gCAAA,EAAmC,OAAO,CAAA,CAAE,CAAA;AAAA,IAC9D;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,gBAAgB,MAAA,EAAqD;AACzE,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,SAAS,eAAA,CAAgB;AAAA,QACpE,IAAA,EAAM;AAAA,OACP,CAAA;AACD,MAAA,OAAO,QAAA,EAAU,QAAQ,EAAC;AAAA,IAC5B,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,6BAAA,EAAgC,OAAO,CAAA,CAAE,CAAA;AAAA,IAC3D;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,gBAAgB,OAAA,EAAmD;AACvE,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,SAAS,cAAA,CAAe;AAAA,QACnE,GAAI,OAAA,IAAW,EAAE,WAAA,EAAa,EAAE,SAAQ;AAAE,OAC3C,CAAA;AACD,MAAA,MAAM,MAAA,GAAS,UAAU,IAAA,EAAM,IAAA,CAAK,OAAK,CAAA,CAAE,KAAA,CAAM,YAAY,OAAO,CAAA;AACpE,MAAA,OAAO,MAAA,IAAU,IAAA;AAAA,IACnB,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,6BAAA,EAAgC,OAAO,CAAA,CAAE,CAAA;AAAA,IAC3D;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,kBAAkB,OAAA,EAA6C;AACnE,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,SAAS,iBAAA,CAAkB;AAAA,QACtE,WAAA,EAAa,EAAE,OAAA;AAAQ,OACxB,CAAA;AACD,MAAA,OAAO,QAAA,EAAU,QAAQ,EAAC;AAAA,IAC5B,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,+BAAA,EAAkC,OAAO,CAAA,CAAE,CAAA;AAAA,IAC7D;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,aAAA,GAA2C;AAC/C,IAAA,IAAI,CAAC,IAAA,CAAK,WAAA,EAAY,EAAG;AACvB,MAAA,MAAM,IAAI,MAAM,gCAAgC,CAAA;AAAA,IAClD;AAEA,IAAA,IAAI;AACF,MAAA,MAAM,WAAW,MAAM,IAAA,CAAK,UAAA,EAAY,GAAA,EAAK,cAAc,aAAA,EAAc;AACzE,MAAA,OAAO,QAAA,EAAU,QAAQ,EAAC;AAAA,IAC5B,SAAS,KAAA,EAAO;AACd,MAAA,MAAM,OAAA,GACJ,KAAA,YAAiB,KAAA,GAAQ,KAAA,CAAM,OAAA,GAAU,wBAAA;AAC3C,MAAA,MAAM,IAAI,KAAA,CAAM,CAAA,0BAAA,EAA6B,OAAO,CAAA,CAAE,CAAA;AAAA,IACxD;AAAA,EACF;AACF,CAAA;AAGO,IAAM,WAAA,GAAc,IAAI,WAAA;;;ACtwBxB,IAAK,OAAA,qBAAAA,QAAAA,KAAL;AACL,EAAAA,SAAA,MAAA,CAAA,GAAO,QAAA;AACP,EAAAA,SAAA,MAAA,CAAA,GAAO,MAAA;AACP,EAAAA,SAAA,QAAA,CAAA,GAAS,eAAA;AACT,EAAAA,SAAA,QAAA,CAAA,GAAS,QAAA;AACT,EAAAA,SAAA,OAAA,CAAA,GAAQ,OAAA;AALE,EAAA,OAAAA,QAAAA;AAAA,CAAA,EAAA,OAAA,IAAA,EAAA;AAsFL,IAAM,yBAAA,GAA4B;AAClC,IAAM,0BAAA,GAA6B;AACnC,IAAM,qBAAA,GAAwB;AAC9B,IAAM,0BAAA,GAA6B;AACnC,IAAM,sBAAA,GAAyB;AAC/B,IAAM,wBAAA,GAA2B;AACjC,IAAM,eAAA,GAAkB;AACxB,IAAM,kBAAA,GAAqB;AAC3B,IAAM,qBAAA,GAAwB","file":"index.js","sourcesContent":["/**\n * Utility functions for Obrew API\n * @module utils\n */\n\nimport { I_ConnectionConfig, I_Connection } from './types'\n\n// Chat events\nexport const SSE_DATA_PREFIX = 'data:'\nexport const SSE_EVENT_PREFIX = 'event:'\nexport const SSE_COMMENT_PREFIX = ':'\n\n/**\n * Default port for Obrew API\n */\nexport const defaultPort = '8008'\n/**\n * Default domain for Obrew API\n * @TODO We need a method to tell whether the app is currently running locally (dev-mode) or hosted on server (web).\n */\nexport const defaultDomain = 'http://localhost'\nexport const DEFAULT_OBREW_CONFIG: I_ConnectionConfig = {\n  domain: defaultDomain,\n  port: defaultPort,\n  version: 'v1',\n  enabled: false, // Disabled by default until connected\n}\nexport const DEFAULT_OBREW_CONNECTION: I_Connection = {\n  config: DEFAULT_OBREW_CONFIG,\n  api: null,\n}\n\n/**\n * Create a fully qualified domain name from stored connection settings\n * @returns The complete origin URL (e.g., \"http://localhost:8008\")\n */\nexport const createDomainName = (config: I_ConnectionConfig): string => {\n  const { port, domain } = config\n  const PORT = port || defaultPort\n  const DOMAIN = domain === '0.0.0.0' ? defaultDomain : domain || defaultDomain\n  const origin = `${DOMAIN}:${PORT}`\n  return origin\n}\n","/**\n * Core API client for Obrew backend services\n * @module api\n */\n\nimport { createDomainName } from './utils'\nimport type {\n  I_API,\n  I_ConnectResponse,\n  I_ServicesResponse,\n  I_ServiceApis,\n  I_GenericAPIRequestParams,\n  T_GenericReqPayload,\n  T_APIConfigOptions,\n  I_ConnectionConfig,\n} from './types'\n\n/**\n * Connect to the Obrew backend server\n * @returns A promise that resolves with connection info or null on failure\n */\nexport const connect = async ({\n  config,\n  signal,\n}: {\n  config: I_ConnectionConfig\n  signal?: AbortSignal\n}): Promise<I_ConnectResponse | null> => {\n  const options = {\n    ...(signal && { signal }),\n    method: 'GET',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  }\n\n  try {\n    const origin = createDomainName(config)\n    const res = await fetch(`${origin}/${config.version}/connect`, options)\n    if (!res.ok) throw new Error(`HTTP error! Status: ${res.status}`)\n    if (!res) throw new Error('No response received.')\n    return res.json()\n  } catch (err) {\n    console.error('[obrew] connectToServer error:', err)\n    return null\n  }\n}\n\n/**\n * Create service API clients from backend configuration\n * @param response - The API configuration from the backend\n * @returns Service API clients or null if configuration is invalid\n */\nexport const createServices = (\n  config: I_ConnectionConfig,\n  response: I_API[] | null\n): I_ServiceApis | null => {\n  if (!response || response.length === 0) return null\n\n  const serviceApis = {} as I_ServiceApis\n\n  // Construct api funcs for each service\n  response.forEach(api => {\n    const origin = createDomainName(config)\n    const apiName = api.name\n    const endpoints: {\n      [key: string]: (args: any) => Promise<Response | null>\n    } & {\n      configs?: T_APIConfigOptions\n    } = {}\n    let res: Response\n\n    // Parse endpoint urls\n    api.endpoints.forEach(endpoint => {\n      // Create a curried fetch function\n      const request = async (\n        args: I_GenericAPIRequestParams<T_GenericReqPayload>\n      ) => {\n        try {\n          const contentType = { 'Content-Type': 'application/json' }\n          const method = endpoint.method\n          const headers = {\n            ...(method === 'POST' && !args?.formData && contentType),\n          }\n          const body = args?.formData\n            ? args.formData\n            : JSON.stringify(args?.body)\n          const signal = args?.signal\n          const queryParams = args?.queryParams\n            ? new URLSearchParams(args?.queryParams).toString()\n            : null\n          const queryUrl = queryParams ? `?${queryParams}` : ''\n          const url = `${origin}${endpoint.urlPath}${queryUrl}`\n\n          res = await fetch(url, {\n            method,\n            mode: 'cors', // no-cors, *, cors, same-origin\n            cache: 'no-cache',\n            credentials: 'same-origin',\n            headers, // { 'Content-Type': 'multipart/form-data' }, // Browser will set this automatically for us for \"formData\"\n            redirect: 'follow',\n            referrerPolicy: 'no-referrer', // no-referrer, *no-referrer-when-downgrade, origin, origin-when-cross-origin, same-origin, strict-origin, strict-origin-when-cross-origin, unsafe-url\n            body,\n            ...(signal && { signal }),\n          })\n\n          // Check no response\n          if (!res)\n            throw new Error(`No response for endpoint ${endpoint.name}.`)\n\n          // Check bad request\n          if (!res?.ok) {\n            // Try to get error details from response body\n            let errorDetail = res?.statusText\n            try {\n              const errorBody = await res.json()\n              if (errorBody?.detail) {\n                errorDetail =\n                  typeof errorBody.detail === 'string'\n                    ? errorBody.detail\n                    : JSON.stringify(errorBody.detail)\n              } else if (errorBody?.message) {\n                errorDetail = errorBody.message\n              }\n            } catch {\n              // If JSON parsing fails, keep statusText\n            }\n            throw new Error(`Something went wrong. ${errorDetail}`)\n          }\n\n          // Check json response\n          const responseType = res.headers.get('content-type')\n          if (res.json && !responseType?.includes('event-stream')) {\n            const result = await res.json()\n\n            if (!result) throw new Error('Something went wrong')\n            // Check failure from obrew api\n            if (typeof result?.success === 'boolean' && !result?.success)\n              throw new Error(\n                `An unexpected error occurred for [${\n                  endpoint.name\n                }] endpoint: ${result?.message ?? result?.detail}`\n              )\n            // Success\n            return result\n          }\n          // Return raw response (for streaming)\n          return res\n        } catch (err) {\n          console.error(`[obrew] Endpoint \"${endpoint.name}\":`, err)\n          return { success: false, message: err }\n        }\n      }\n\n      // Add request function for this endpoint\n      endpoints[endpoint.name] = request\n      // Set api configs\n      endpoints.configs = api.configs || {}\n    })\n    // Set api callbacks\n    serviceApis[apiName] = endpoints\n  })\n\n  return serviceApis\n}\n\n/**\n * Get the API configuration from the backend\n * @returns A promise that resolves with the API array or null on failure\n */\nexport const fetchAPIConfig = async (\n  config: I_ConnectionConfig\n): Promise<I_API[] | null> => {\n  const options = {\n    method: 'GET',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  }\n\n  try {\n    const endpoint = `/${config.version}/services/api`\n    const url = createDomainName(config)\n    const res = await fetch(`${url}${endpoint}`, options)\n    if (!res.ok) throw new Error(`HTTP error! Status: ${res.status}`)\n    if (!res) throw new Error(`No response from ${endpoint}`)\n    const result: I_ServicesResponse = await res.json()\n    const success = result?.success\n    if (!success) return null\n    const apis = result.data\n    return apis\n  } catch (err) {\n    console.error('[obrew] fetchAPIConfig error:', err)\n    return null\n  }\n}\n","import { createServices, fetchAPIConfig, connect as apiConnect } from './api'\nimport {\n  I_Connection,\n  I_ConnectionConfig,\n  Message,\n  I_InferenceGenerateOptions,\n  I_Message,\n  I_HardwareInfo,\n  I_Text_Settings,\n  T_InstalledTextModel,\n} from './types'\nimport {\n  DEFAULT_OBREW_CONNECTION,\n  SSE_COMMENT_PREFIX,\n  SSE_DATA_PREFIX,\n  SSE_EVENT_PREFIX,\n} from './utils'\n\ntype onChatResponseCallback = (text: string | ((t: string) => void)) => void\n\n/**\n * ObrewClient responsibilities:\n * 1. Handle connections and server config (track host/port in mem)\n * 2. Provide wrapper functions around obrew api\n * 3. Handle teardown/cleanup of network calls, etc when client unmounts/disconnects\n */\nclass ObrewClient {\n  private hasConnected = false\n  private abortController: AbortController | null = null\n  private connection: I_Connection = DEFAULT_OBREW_CONNECTION\n\n  // Data Methods //\n\n  /**\n   * Check if service is connected\n   */\n  isConnected(): boolean {\n    return (\n      this.hasConnected &&\n      !!this.connection.api &&\n      this.connection.config.enabled\n    )\n  }\n\n  /**\n   * Return the current connection\n   */\n  getConnection(): I_Connection {\n    return this.connection\n  }\n\n  // Connection Methods //\n\n  /**\n   * Initialize connection to Obrew backend.\n   */\n  async connect({\n    config,\n    signal,\n  }: {\n    config: I_ConnectionConfig\n    signal?: AbortSignal\n  }): Promise<boolean> {\n    if (this.hasConnected) {\n      console.log('[obrew-client] Connection is already active!')\n      return false\n    }\n    try {\n      // Attempt handshake connection\n      const connSuccess = await apiConnect({\n        config,\n        ...(signal && { signal }),\n      })\n      if (!connSuccess?.success) throw new Error(connSuccess?.message)\n      // Get API configuration and create services\n      const apiConfig = await fetchAPIConfig(config)\n      if (!apiConfig) throw new Error('No api returned.')\n      const serviceApis = createServices(config, apiConfig)\n      // Success\n      if (serviceApis) {\n        this.hasConnected = true\n        // Store config in connection after successful connect\n        const enabledConfig = { ...config, enabled: true }\n        this.connection = { config: enabledConfig, api: serviceApis }\n        console.log(\n          '[obrew-client] Successfully connected to Obrew API\\n',\n          config\n        )\n        return true\n      }\n      // Failed\n      return false\n    } catch (error) {\n      console.error('[obrew-client] Failed to connect to Obrew:', error)\n      this.hasConnected = false\n      return false\n    }\n  }\n\n  /**\n   * Ping server to check if it's responsive.\n   * Used for server discovery and health checks.\n   */\n  async ping(timeout = 5000): Promise<{\n    success: boolean\n    responseTime?: number\n    error?: string\n  }> {\n    // const {domain: url, port} = this.connection.config\n    // const endpointHealth = `${url}:${port}/api/health`\n    const controller = new AbortController()\n    const timeoutId = setTimeout(() => controller.abort(), timeout)\n    const startTime = performance.now()\n\n    try {\n      const connSuccess = await apiConnect({\n        config: this.connection.config,\n        signal: controller.signal,\n      })\n      clearTimeout(timeoutId)\n      // Check\n      if (!connSuccess?.success) throw new Error(connSuccess?.message)\n      return {\n        success: true,\n        responseTime: Math.round(performance.now() - startTime),\n      }\n    } catch (error) {\n      clearTimeout(timeoutId)\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : 'Connection failed',\n      }\n    }\n  }\n\n  /**\n   * Cancel ongoing request\n   */\n  cancelRequest(): void {\n    if (this.abortController) {\n      this.abortController.abort()\n      this.abortController = null\n    }\n  }\n\n  /**\n   * Disconnect from service\n   */\n  disconnect(): void {\n    this.cancelRequest()\n    this.connection.api = null\n    this.hasConnected = false\n  }\n\n  // Core Helper Methods //\n\n  /**\n   * Extract text from various response formats\n   * Handles multiple response types from different API endpoints\n   */\n  private extractTextFromResponse(response: any): string {\n    // Handle NonStreamPlayground format\n    if (response.text) {\n      return response.text\n    }\n\n    // Handle NonStreamChatbotResponse format\n    if (response.response) {\n      return response.response\n    }\n\n    // Handle GenericAPIResponse format\n    if (response.data && typeof response.data === 'string') {\n      return response.data\n    }\n\n    // Handle raw choices array\n    if (response.choices && Array.isArray(response.choices)) {\n      return (\n        response.choices[0]?.text || response.choices[0]?.message?.content || ''\n      )\n    }\n\n    // Fallback to string conversion\n    return String(response)\n  }\n\n  /**\n   * Unified streaming response handler for SSE (Server-Sent Events)\n   * Supports both simple text accumulation and advanced callback-based streaming\n   * https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Using_readable_streams\n   * @param response - The Response object containing the stream\n   * @param options - Configuration options for handling the stream\n   * @param abortRef - Optional external AbortController to cancel the stream (separate from class's abortController)\n   */\n  private async handleStreamResponse(\n    response: Response,\n    options?: {\n      onData?: (str: string) => void | Promise<void>\n      onFinish?: () => void | Promise<void>\n      onEvent?: (str: string) => void | Promise<void>\n      onComment?: (str: string) => void | Promise<void>\n      extractText?: boolean // If true, accumulate and return text\n    },\n    abortRef?: AbortController | null\n  ): Promise<string> {\n    const reader = response.body?.getReader()\n    if (!reader) {\n      throw new Error('No reader available for streaming response')\n    }\n\n    const decoder = new TextDecoder('utf-8')\n    let fullText = ''\n    const extractText = options?.extractText ?? true\n\n    try {\n      let readingBuffer = await reader.read()\n\n      // Check both external abortRef (if provided) and internal abortController\n      while (!readingBuffer.done && !abortRef?.signal.aborted) {\n        try {\n          const chunk =\n            typeof readingBuffer.value === 'string'\n              ? readingBuffer.value\n              : decoder.decode(readingBuffer.value, { stream: true })\n\n          const lines = chunk.split('\\n')\n\n          for (const line of lines) {\n            // Handle SSE comments\n            if (line?.startsWith(SSE_COMMENT_PREFIX)) {\n              const comment = line.slice(SSE_COMMENT_PREFIX.length).trim()\n              await options?.onComment?.(comment)\n            }\n\n            // Handle SSE events\n            if (line?.startsWith(SSE_EVENT_PREFIX)) {\n              const eventName = line.slice(SSE_EVENT_PREFIX.length).trim()\n              await options?.onEvent?.(eventName)\n            }\n\n            // Handle SSE data\n            if (line?.startsWith(SSE_DATA_PREFIX)) {\n              const eventData = line.slice(SSE_DATA_PREFIX.length).trim()\n\n              // Check for stream completion marker\n              if (eventData === '[DONE]') {\n                break\n              }\n\n              // Call onData callback if provided\n              await options?.onData?.(eventData)\n\n              // Also accumulate text if extractText is enabled\n              if (extractText) {\n                try {\n                  const parsed = JSON.parse(eventData)\n                  fullText += this.extractTextFromResponse(parsed)\n                } catch {\n                  // If not JSON, treat as plain text\n                  fullText += eventData\n                }\n              }\n            }\n\n            // Support legacy \"data: \" format (without SSE prefix constant)\n            if (\n              !line.startsWith(SSE_DATA_PREFIX) &&\n              line.startsWith('data: ')\n            ) {\n              const data = line.slice(6)\n              if (data === '[DONE]') break\n\n              await options?.onData?.(data)\n\n              if (extractText) {\n                try {\n                  const parsed = JSON.parse(data)\n                  fullText += this.extractTextFromResponse(parsed)\n                } catch {\n                  fullText += data\n                }\n              }\n            }\n          }\n        } catch (err) {\n          console.log('[obrew-client] Error reading stream data buffer:', err)\n        }\n\n        readingBuffer = await reader.read()\n      }\n\n      // Cancel if not done (e.g., aborted)\n      if (!readingBuffer.done) {\n        await reader.cancel()\n      }\n    } finally {\n      reader.releaseLock()\n    }\n\n    // Call finish callback\n    await options?.onFinish?.()\n\n    return fullText\n  }\n\n  // Core API Methods //\n\n  /**\n   * Send a message and get AI response\n   * Handles both streaming and non-streaming responses\n   */\n  async sendMessage(\n    messages: Message[],\n    options?: Partial<I_InferenceGenerateOptions>\n  ): Promise<string> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    // Create new abort controller for this request\n    this.abortController = new AbortController()\n\n    try {\n      const response = await this.connection?.api?.textInference.generate({\n        body: {\n          messages,\n          responseMode: 'chat',\n          temperature: 0.7,\n          max_tokens: 2048,\n          stream: false, // @TODO Non-streaming for now\n          ...options,\n        },\n        signal: this.abortController.signal,\n      })\n\n      if (!response) {\n        throw new Error('No response from AI service')\n      }\n\n      // Handle different response types\n      if (typeof response === 'string') {\n        return response\n      }\n\n      // Handle Response object (streaming)\n      // Check if it's a Response-like object with headers and body\n      if (\n        typeof response === 'object' &&\n        response !== null &&\n        'headers' in response &&\n        'body' in response\n      ) {\n        const httpResponse = response as Response\n        const contentType = httpResponse.headers.get('content-type')\n        if (contentType?.includes('event-stream')) {\n          // Handle streaming response\n          return await this.handleStreamResponse(httpResponse)\n        } else {\n          // Handle JSON response\n          const data = await httpResponse.json()\n          return this.extractTextFromResponse(data)\n        }\n      }\n\n      // Handle structured response objects\n      return this.extractTextFromResponse(response)\n    } catch (error) {\n      if (error instanceof Error && error.name === 'AbortError') {\n        throw new Error('Request was cancelled')\n      }\n      throw error\n    }\n  }\n\n  /**\n   * Handle non-streaming result\n   * Extracts text using the unified extraction logic\n   */\n  onNonStreamResult({\n    result,\n    setResponseText,\n  }: {\n    result: any\n    setResponseText?: onChatResponseCallback\n  }) {\n    console.log('[obrew-client] non-stream finished!')\n    const text = this.extractTextFromResponse(result)\n    if (text) setResponseText?.(text)\n  }\n\n  /**\n   * Handle streaming result\n   * Extracts text from individual stream chunks\n   */\n  async onStreamResult({\n    result,\n    setResponseText,\n  }: {\n    result: string\n    setResponseText?: onChatResponseCallback\n  }) {\n    try {\n      // Server sends data back\n      const parsedResult = result ? JSON.parse(result) : null\n      const data = parsedResult?.data\n      const eventName = parsedResult?.event\n\n      // Use unified text extraction\n      const text = this.extractTextFromResponse(data || parsedResult)\n\n      if (text)\n        setResponseText?.(prevText => {\n          // Overwrite prev response if final content is received\n          if (eventName === 'GENERATING_CONTENT') return text\n          return (prevText += text)\n        })\n      return\n    } catch (err) {\n      console.log(\n        '[obrew-client] onStreamResult err:',\n        typeof result,\n        ' | ',\n        err\n      )\n      return\n    }\n  }\n\n  onStreamEvent(eventName: string) {\n    switch (eventName) {\n      case 'FEEDING_PROMPT':\n        break\n      case 'GENERATING_TOKENS':\n        break\n      case 'GENERATING_CONTENT':\n        break\n      default:\n        break\n    }\n    console.log(`[obrew-client] onStreamEvent ${eventName}`)\n  }\n\n  async append(\n    prompt: I_Message,\n    setEventState: (ev: string) => void,\n    setIsLoading: (b: boolean) => void\n  ) {\n    if (!prompt) return\n\n    // Create an id for the assistant's response\n    // setResponseId(nanoid())\n\n    // Create new message for user's prompt\n    const newUserMsg: I_Message = {\n      id: prompt.id,\n      role: prompt.role,\n      content: prompt.content, // always assign prompt content w/o template\n      createdAt: prompt.createdAt,\n      ...(prompt.role === 'user' && { username: prompt?.username || '' }),\n      ...(prompt.role === 'assistant' && { modelId: prompt?.modelId || '' }),\n    }\n    // Add to/Update messages list\n    // setCurrentMessages(prev => {\n    //   if (!currentThreadId.current) {\n    //     return [newUserMsg]\n    //   }\n    //   return [...prev, newUserMsg]\n    // })\n\n    // Create new thread\n    // setThreads({})\n\n    // Request response\n    try {\n      // Reset state\n      // setResponseText('')\n      // setIsLoading(true)\n      // abortRef.current = false\n\n      // Send request completion for prompt\n      console.log(\n        '[obrew-client] Sending request to inference server...',\n        newUserMsg\n      )\n      // const mode =\n      //   settings?.attention?.response_mode || DEFAULT_CONVERSATION_MODE\n      // const options: I_InferenceGenerateOptions = {\n      //   responseMode: mode,\n      //   toolResponseMode: settings?.attention?.tool_response_mode,\n      //   toolUseMode: settings?.attention?.tool_use_mode,\n      //   tools: settings?.tools?.assigned,\n      //   prompt: prompt?.content,\n      //   promptTemplate: settings?.prompt?.promptTemplate?.text,\n      //   systemMessage: settings?.system?.systemMessage,\n      //   memory: settings?.memory,\n      //   ...settings?.performance,\n      //   ...settings?.response,\n      // }\n\n      // @TODO Call a specific agent by name using sendMessage()\n      const response = {} as Response // await this.sendMessage(...)\n      // console.log('[obrew-client] Prompt response', response)\n\n      // Check success if streamed\n      if (response?.body?.getReader) {\n        // Process the stream into text tokens\n        await this.handleStreamResponse(\n          response,\n          {\n            onData: (res: string) => this.onStreamResult({ result: res }),\n            onFinish: async () => {\n              console.log('[obrew-client] stream finished!')\n              return\n            },\n            onEvent: async (str: string) => {\n              this.onStreamEvent(str)\n              const displayEventStr = str.replace(/_/g, ' ') + '...'\n              if (str) setEventState(displayEventStr)\n            },\n            onComment: async (str: string) => {\n              console.log('[obrew-client] onComment', str)\n              return\n            },\n            extractText: false, // Don't accumulate text, use callbacks instead\n          },\n          this.abortController\n        )\n      }\n\n      // Check success if not streamed\n      else this.onNonStreamResult({ result: response })\n\n      // Save final results\n      // setCurrentMessages()\n\n      // Finish\n      setIsLoading(false)\n      return\n    } catch (err) {\n      setIsLoading(false)\n      console.log(`[obrew-client] ${err}`)\n      // toast.error(`Prompt request error: \\n ${err}`)\n    }\n  }\n\n  // End @TODO //\n\n  stopChat() {\n    this.abortController?.abort()\n    this.connection?.api?.textInference.stop()\n  }\n\n  /**\n   * Install/download a model from a repository\n   * @param repoId - The repository ID of the model to install (e.g., \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\")\n   * @param filename - Optional specific filename to download from the repository\n   * @returns The download result message\n   * @throws Error if not connected or download fails\n   */\n  async installModel(repoId: string, filename?: string): Promise<string> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      // Note: Server expects snake_case parameters\n      const body: { repo_id: string; filename?: string } = { repo_id: repoId }\n      if (filename) {\n        body.filename = filename\n      }\n\n      const response = await this.connection?.api?.textInference.download({\n        body,\n      })\n\n      // Server returns {success: true, message: \"...\", data: null}\n      // Return the message field which contains the success info\n      if (response?.message) {\n        return response.message\n      }\n\n      // Fallback to data field if message is not available\n      if (response?.data) {\n        return response.data\n      }\n\n      throw new Error('No response data from model installation')\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to install model: ${message}`)\n    }\n  }\n\n  /**\n   * Uninstall/delete a model from server\n   * @param repoId - The repository ID of the model to delete\n   * @param filename - The filename of the model to delete\n   * @throws Error if not connected or deletion fails\n   */\n  async uninstallModel(repoId: string, filename: string): Promise<void> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      await this.connection?.api?.textInference.delete({\n        body: {\n          repoId,\n          filename,\n        },\n      })\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to uninstall model: ${message}`)\n    }\n  }\n\n  /**\n   * Load a text model\n   * @param modelPath - The file path to the model\n   * @param modelId - The unique identifier for the model\n   * raw_input: Optional[bool] = False  # user can send manually formatted messages\n     responseMode: Optional[str] = DEFAULT_CHAT_MODE\n     toolUseMode: Optional[str] = DEFAULT_TOOL_USE_MODE\n     toolSchemaType: Optional[str] = DEFAULT_TOOL_SCHEMA_TYPE\n     init: LoadTextInferenceInit\n     call: LoadTextInferenceCall\n     messages: Optional[List[ChatMessage]] = None\n   * @throws Error if not connected or model loading fails\n   */\n  async loadModel(modelPath: string, modelId: string): Promise<void> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const results = await this.connection?.api?.textInference.load({\n        body: {\n          modelPath,\n          modelId,\n          init: {\n            n_ctx: 4096,\n            n_threads: 4,\n            n_gpu_layers: -1,\n          },\n          call: {\n            temperature: 0.7,\n            max_tokens: 2048,\n          },\n        },\n      })\n      if (!results) throw new Error('No results for loaded model.')\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to load model: ${message}`)\n    }\n  }\n\n  /**\n   * Unload the currently loaded text model\n   * @throws Error if not connected or unloading fails\n   */\n  async unloadModel(): Promise<void> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      await this.connection?.api?.textInference.unload()\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to unload model: ${message}`)\n    }\n  }\n\n  /**\n   * Get currently loaded model info\n   * @returns The loaded model data, or null if no model is loaded\n   * @throws Error if not connected or request fails\n   */\n  async getLoadedModel() {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const response = await this.connection?.api?.textInference.model()\n      return response?.data || null\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to get loaded model: ${message}`)\n    }\n  }\n\n  /**\n   * Get list of installed models\n   * @returns Array of installed models (empty array if none installed)\n   * @throws Error if not connected or request fails\n   */\n  async getInstalledModels(): Promise<T_InstalledTextModel[]> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const response = await this.connection?.api?.textInference.installed()\n      const result = response?.data\n      if (!result || result.length <= 0) throw new Error('No results.')\n      return result\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to get installed models: ${message}`)\n    }\n  }\n\n  /**\n   * Save agent/bot configuration settings\n   * @param config - The agent configuration settings to save\n   * @returns Array of all saved agent configurations\n   * @throws Error if not connected or save fails\n   */\n  async saveAgentConfig(config: I_Text_Settings): Promise<I_Text_Settings[]> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const response = await this.connection?.api?.storage?.saveBotSettings({\n        body: config,\n      })\n      return response?.data || []\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to save agent config: ${message}`)\n    }\n  }\n\n  /**\n   * Load agent/bot configuration settings\n   * @param botName - Optional bot name to filter configurations\n   * @returns Array of agent configurations (empty array if none found)\n   * @throws Error if not connected or load fails\n   */\n  async loadAgentConfig(botName?: string): Promise<I_Text_Settings | null> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const response = await this.connection?.api?.storage?.getBotSettings({\n        ...(botName && { queryParams: { botName } }),\n      })\n      const config = response?.data?.find(c => c.model.botName === botName)\n      return config || null\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to load agent config: ${message}`)\n    }\n  }\n\n  /**\n   * Delete agent/bot configuration settings\n   * @param botName - The bot name to delete\n   * @returns Array of remaining agent configurations\n   * @throws Error if not connected or deletion fails\n   */\n  async deleteAgentConfig(botName: string): Promise<I_Text_Settings[]> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const response = await this.connection?.api?.storage?.deleteBotSettings({\n        queryParams: { botName },\n      })\n      return response?.data || []\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to delete agent config: ${message}`)\n    }\n  }\n\n  /**\n   * Get hardware information (GPU details, VRAM, etc.)\n   * @returns Array of hardware information (empty array if no hardware found)\n   * @throws Error if not connected or audit fails\n   */\n  async auditHardware(): Promise<I_HardwareInfo[]> {\n    if (!this.isConnected()) {\n      throw new Error('Not connected to Obrew service')\n    }\n\n    try {\n      const response = await this.connection?.api?.textInference.auditHardware()\n      return response?.data || []\n    } catch (error) {\n      const message =\n        error instanceof Error ? error.message : 'Unknown error occurred'\n      throw new Error(`Failed to audit hardware: ${message}`)\n    }\n  }\n}\n\n// Export singleton instance\nexport const obrewClient = new ObrewClient()\n","/**\n * Type definitions for Obrew API\n * @module types\n */\n\n// ============================================================================\n// Message & Thread Types\n// ============================================================================\n\nexport type Message = {\n  id: string\n  createdAt?: Date | undefined\n  content: string\n  role: 'system' | 'user' | 'assistant'\n}\n\nexport interface I_Message {\n  id: string\n  content: string\n  role: 'system' | 'user' | 'assistant'\n  createdAt?: string\n  modelId?: string // for assistant msg\n  username?: string // for user msg\n}\n\nexport interface I_Thread {\n  id: string\n  userId: string\n  createdAt: string\n  title: string\n  summary: string\n  numMessages: number\n  messages: Array<I_Message>\n  sharePath?: string\n}\n\n// ============================================================================\n// Model Types\n// ============================================================================\n\nexport enum ModelID {\n  GPT3 = 'gpt3.5',\n  GPT4 = 'gpt4',\n  GPTNeo = 'gpt-neoxt-20B', // together/\n  Cohere = 'xlarge', // cohere/\n  Local = 'local', // 3rd party, local server\n}\n\nexport type T_ModelConfig = {\n  repoId: string\n  name: string\n  description?: string\n  messageFormat?: string\n}\n\nexport interface I_ModelConfigs {\n  [key: string]: T_ModelConfig\n}\n\nexport type T_InstalledTextModel = {\n  repoId: string\n  savePath: { [key: string]: string }\n  numTimesRun: number\n  isFavorited: boolean\n  validation: string\n  modified: string\n  size: number\n  endChunk: number\n  progress: number\n  tokenizerPath: string\n  checksum: string\n}\n\n// ============================================================================\n// LLM Configuration Types\n// ============================================================================\n\nexport interface I_LLM_Init_Options {\n  n_gpu_layers?: number\n  use_mlock?: boolean\n  seed?: number\n  n_ctx?: number\n  n_batch?: number\n  n_threads?: number\n  offload_kqv?: boolean\n  cache_type_k?: string\n  cache_type_v?: string\n  verbose?: boolean\n}\n\nexport interface I_Response_State {\n  temperature?: number\n  max_tokens?: number\n  top_p?: number\n  echo?: boolean\n  stop?: string\n  repeat_penalty?: number\n  top_k?: number\n  stream?: boolean\n  min_p?: number\n  presence_penalty?: number // 1.0\n  frequency_penalty?: number // 1.0\n  tfs_z?: number\n  mirostat_tau?: number\n  grammar?: string\n}\n\nexport interface I_LLM_Call_Options extends I_Response_State {\n  prompt?: string\n  messages?: Message[]\n  suffix?: string\n  model?: ModelID\n  promptTemplate?: string\n  systemMessage?: string\n  response_mode?: string\n}\n\nexport interface I_LLM_Options {\n  init?: I_LLM_Init_Options\n  call?: I_LLM_Call_Options\n}\n\n// ============================================================================\n// Conversation & Inference Types\n// ============================================================================\n\nexport const DEFAULT_CONVERSATION_MODE = 'instruct'\nexport const DEFAULT_TOOL_RESPONSE_MODE = 'answer'\nexport const BASE_RETRIEVAL_METHOD = 'base'\nexport const AUGMENTED_RETRIEVAL_METHOD = 'augmented'\nexport const AGENT_RETRIEVAL_METHOD = 'agent'\nexport const DEFAULT_RETRIEVAL_METHOD = BASE_RETRIEVAL_METHOD\nexport const NATIVE_TOOL_USE = 'native'\nexport const UNIVERSAL_TOOL_USE = 'universal'\nexport const DEFAULT_TOOL_USE_MODE = UNIVERSAL_TOOL_USE\n\nexport type T_ConversationMode = 'instruct' | 'chat' | 'collab'\nexport type T_ToolResponseMode = 'answer' | 'result'\nexport type T_ToolUseMode = typeof UNIVERSAL_TOOL_USE | typeof NATIVE_TOOL_USE\nexport type T_ToolSchemaType = 'json' | 'typescript'\n\nexport interface I_InferenceGenerateOptions extends T_LLM_InferenceOptions {\n  responseMode?: T_ConversationMode\n  toolResponseMode?: T_ToolResponseMode\n  toolUseMode?: T_ToolUseMode\n  messageFormat?: string\n  memory?: I_Knowledge_State\n  tools?: string[]\n}\n\nexport type T_LLM_InferenceOptions = I_LLM_Call_Options & I_LLM_Init_Options\n\nexport interface I_LoadTextModelRequestPayload {\n  responseMode?: T_ConversationMode\n  toolUseMode?: T_ToolUseMode\n  toolSchemaType?: T_ToolSchemaType\n  messages?: Message[]\n  raw_input?: boolean\n  modelPath: string\n  modelId: string\n  init: I_LLM_Init_Options\n  call: I_LLM_Call_Options\n}\n\nexport interface I_LoadedModelRes {\n  modelId: string\n  modelName: string\n  responseMode: T_ConversationMode\n  modelSettings: I_LLM_Init_Options\n  generateSettings: I_LLM_Call_Options\n}\n\n// ============================================================================\n// Response Types\n// ============================================================================\n\nexport interface I_NonStreamChatbotResponse {\n  metadata: { [key: string]: { order: number; sourceId: string } }\n  response: string\n  source_nodes: Array<any>\n}\n\nexport interface I_NonStreamPlayground {\n  additional_kwargs: any\n  raw: {\n    choices: Array<any>\n    created: number\n    id: string\n    model: string\n    object: string\n    usage: {\n      completion_tokens: number\n      prompt_tokens: number\n      total_tokens: number\n    }\n  }\n  delta: number | null\n  logprobs: any\n  text: string\n}\n\nexport interface I_GenericAPIResponse<DataResType> {\n  success: boolean\n  message: string\n  data: DataResType\n}\n\n// ============================================================================\n// Request Types\n// ============================================================================\n\nexport type T_GenericDataRes = any\nexport type T_GenericReqPayload = { [key: string]: any }\n\nexport interface I_GenericAPIRequestParams<Payload> {\n  queryParams?: Payload\n  formData?: FormData\n  body?: Payload\n  signal?: AbortSignal\n}\n\nexport type T_GenericAPIRequest<ReqPayload, DataResType> = (\n  props?: I_GenericAPIRequestParams<ReqPayload>\n) => Promise<I_GenericAPIResponse<DataResType> | null>\n\nexport type T_SaveChatThreadAPIRequest = (props: {\n  body: {\n    threadId: string\n    thread: I_Thread\n  }\n}) => Promise<I_GenericAPIResponse<T_GenericDataRes>>\n\nexport type T_GetChatThreadAPIRequest = (props: {\n  queryParams: {\n    threadId?: string | null\n  }\n}) => Promise<I_GenericAPIResponse<I_Thread[]>>\n\nexport type T_DeleteChatThreadAPIRequest = (props: {\n  queryParams: {\n    threadId?: string | null\n  }\n}) => Promise<I_GenericAPIResponse<I_Thread[]>>\n\n// ============================================================================\n// Knowledge & Memory Types\n// ============================================================================\n\nexport interface I_Knowledge_State {\n  ids: string[] // collection names\n}\n\nexport interface I_RAG_Strat_State {\n  similarity_top_k: number\n  response_mode: string | undefined\n}\n\nexport interface I_ChunkMetadata {\n  _node_type: string\n  _node_content: any\n  sourceId: string\n  ref_doc_id: string\n  order: number\n}\n\nexport interface I_Source {\n  id: string\n  document_name: string\n  embedding_model: string\n  checksum: string\n  urlPath: string\n  source_file_name: string\n  source_file_path: string\n  file_path: string\n  file_type: string\n  file_name: string\n  file_size: number\n  modified_last: string\n  created_at: string\n  description: string\n  tags: string\n  chunkIds: Array<string>\n}\n\nexport interface I_DocumentChunk {\n  text: string\n  id: string\n  metadata: I_ChunkMetadata\n}\n\nexport interface I_Collection {\n  id: string\n  name: string\n  metadata: {\n    description: string\n    embedding_model: string\n    tags: string\n    icon: string\n    sources: Array<I_Source>\n    created_at?: string\n    sharePath?: string\n    favorites?: number\n    createdAt?: string\n  }\n}\n\n// ============================================================================\n// Tool Types\n// ============================================================================\n\nexport type T_InputOptionTypes =\n  | 'options-sel'\n  | 'options-multi'\n  | 'options-button'\n  | 'text'\n  | 'text-multi'\n\nexport type T_Tool_Param_Option = string[] | number[]\n\nexport interface I_Tool_Parameter {\n  name: string\n  title: string\n  description: string\n  type: string\n  placeholder?: string\n  input_type?: T_InputOptionTypes\n  default_value?: any\n  value?: any\n  min_value?: string | number\n  max_value?: string | number\n  options_source?: string\n  options_description?: string[]\n  options?: string[]\n  items?: any[]\n}\n\nexport interface I_Tool_Def_Parameter extends I_Tool_Parameter {\n  value?: any\n}\n\nexport interface I_ToolFunctionSchemaRes {\n  params: I_Tool_Parameter[]\n  description?: string | undefined\n  params_schema?: any | undefined\n  params_example?: any | undefined\n  output_type?: string[]\n}\n\nexport interface I_Tool_Definition extends I_ToolFunctionSchemaRes {\n  name: string\n  path: string\n  id?: string | undefined // assigned on tool save\n}\n\n// ============================================================================\n// Settings Types\n// ============================================================================\n\nexport type T_PromptTemplate = {\n  id: string\n  name: string\n  text: string\n}\n\nexport type T_SystemPrompt = {\n  id: string\n  name: string\n  text: string\n}\n\nexport interface I_PromptTemplates {\n  [key: string]: T_PromptTemplate[]\n}\n\nexport type T_SystemPrompts = {\n  presets: { [key: string]: T_SystemPrompt[] }\n}\n\nexport type I_Prompt_State = {\n  promptTemplate: T_PromptTemplate\n}\n\nexport interface I_Model_State {\n  id: string | undefined\n  botName?: string\n  filename: string | undefined\n}\n\nexport interface I_System_State {\n  systemMessage: string | undefined\n  systemMessageName: string | undefined\n}\n\nexport interface I_Attention_State {\n  tool_use_mode: T_ToolUseMode\n  tool_response_mode: T_ToolResponseMode\n  response_mode: T_ConversationMode\n}\n\nexport interface I_Tools_Inference_State {\n  assigned: string[]\n}\n\nexport interface I_Text_Settings {\n  tools: I_Tools_Inference_State\n  attention: I_Attention_State\n  performance: I_LLM_Init_Options\n  system: I_System_State\n  model: I_Model_State\n  prompt: I_Prompt_State\n  response: I_Response_State\n  memory: I_Knowledge_State\n}\n\n// ============================================================================\n// API Configuration Types\n// ============================================================================\n\nexport interface I_ConnectionConfig {\n  domain: string\n  port: string\n  version: string\n  enabled: boolean\n}\n\nexport interface I_Connection {\n  config: I_ConnectionConfig\n  api: I_ServiceApis | null\n}\n\nexport type T_APIConfigOptions = {\n  chunkingStrategies?: Array<string>\n  domain?: string\n  port?: string\n}\n\nexport interface I_Endpoint {\n  name: string\n  urlPath: string\n  method: string\n}\n\nexport interface I_API {\n  name: string\n  port: number\n  endpoints: Array<I_Endpoint>\n  configs?: T_APIConfigOptions\n}\n\nexport interface I_ServicesResponse {\n  success: boolean\n  message: string\n  data: Array<I_API>\n}\n\nexport interface I_ConnectResponse {\n  success: boolean\n  message: string\n  data: { docs: string }\n}\n\n// ============================================================================\n// Hardware Types\n// ============================================================================\n\nexport interface I_HardwareInfo {\n  gpu_type: string\n  gpu_name: string\n  driver_ver: string\n  manufacturer: string\n  dac_type: string\n  pnp_device_id: string\n  id?: number\n  vram_total?: number\n  vram_used?: number\n  vram_free?: number\n}\n\nexport interface I_HardwareAuditResponse {\n  success: boolean\n  message: string\n  data: I_HardwareInfo[]\n}\n\n// ============================================================================\n// Service API Types\n// ============================================================================\n\nexport type T_Endpoint = { [key: string]: any }\n\nexport interface I_BaseServiceApis {\n  [key: string]: T_Endpoint\n}\n\nexport type T_TextInferenceAPIRequest = (props: {\n  body: I_InferenceGenerateOptions\n  signal: AbortSignal\n}) => Promise<\n  | Response\n  | I_NonStreamPlayground\n  | I_NonStreamChatbotResponse\n  | string // a JSON string\n  | I_GenericAPIResponse<any>\n  | null\n>\n\nexport interface I_DeleteTextModelReqPayload {\n  repoId: string\n  filename: string\n}\n\nexport interface I_ToolSchemaReqPayload {\n  filename: string\n}\n\nexport interface I_ServiceApis extends I_BaseServiceApis {\n  /**\n   * Use to query the text inference engine\n   */\n  textInference: {\n    generate: T_TextInferenceAPIRequest\n    stop: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    load: T_GenericAPIRequest<\n      I_LoadTextModelRequestPayload,\n      I_GenericAPIResponse<undefined>\n    >\n    unload: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    model: T_GenericAPIRequest<T_GenericReqPayload, I_LoadedModelRes> // Currently loaded text model\n    modelExplore: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    installed: T_GenericAPIRequest<T_GenericReqPayload, T_InstalledTextModel[]> // List of currently installed text models\n    getModelMetadata: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    getModelInfo: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    download: T_GenericAPIRequest<T_GenericReqPayload, string>\n    delete: T_GenericAPIRequest<I_DeleteTextModelReqPayload, T_GenericDataRes>\n    getModelConfigs: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    auditHardware: T_GenericAPIRequest<T_GenericReqPayload, I_HardwareInfo[]>\n    // getPromptTemplates: T_GenericAPIRequest<\n    //   T_GenericReqPayload,\n    //   T_GenericDataRes\n    // >;\n    // getSystemPrompts: T_GenericAPIRequest<\n    //   T_GenericReqPayload,\n    //   T_GenericDataRes\n    // >;\n  }\n  /**\n   * Use to add/create/update/delete embeddings from database\n   */\n  memory: {\n    addDocument: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    getChunks: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    updateDocument: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    deleteDocuments: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    getAllCollections: T_GenericAPIRequest<\n      T_GenericReqPayload,\n      T_GenericDataRes\n    >\n    addCollection: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    getCollection: T_GenericAPIRequest<T_GenericReqPayload, I_Collection>\n    deleteCollection: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    fileExplore: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    wipe: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    configs: {\n      chunkingStrategies: Array<string>\n    }\n  }\n  /**\n   * Use to persist data specific to the app itself\n   */\n  storage: {\n    getToolSchema: T_GenericAPIRequest<\n      I_ToolSchemaReqPayload,\n      I_ToolFunctionSchemaRes\n    >\n    getToolFunctions: T_GenericAPIRequest<T_GenericReqPayload, T_GenericDataRes>\n    saveToolSettings?: T_GenericAPIRequest<T_GenericReqPayload, null>\n    getToolSettings?: T_GenericAPIRequest<\n      T_GenericReqPayload,\n      I_Tool_Definition[]\n    >\n    deleteToolSettings?: T_GenericAPIRequest<T_GenericReqPayload, null>\n    getBotSettings: T_GenericAPIRequest<T_GenericReqPayload, I_Text_Settings[]>\n    deleteBotSettings: T_GenericAPIRequest<\n      T_GenericReqPayload,\n      I_Text_Settings[]\n    >\n    saveBotSettings: T_GenericAPIRequest<T_GenericReqPayload, I_Text_Settings[]>\n    saveChatThread: T_SaveChatThreadAPIRequest\n    getChatThread: T_GetChatThreadAPIRequest\n    deleteChatThread: T_DeleteChatThreadAPIRequest\n  }\n}\n"]}